{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling TCGA data\n",
    "### 0. Your input\n",
    "- Choose the folder path your analysis results should be stored in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input your analysis folder (e.g. analysis_path = '/home/user/user_name1/TCGA_analysis')\n",
    "analysis_path = '/home/alex/Dokumente/02_OLCIR/00_tcga_download_helper/07_improved_TCGA_download_helper_v1_data'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(analysis_path):\n",
    "    print('The analysis path is non-existent. Please check again and input your new analysis path.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a folder called \"sample_sheets\" in your analysis path, creates the folders \"manifests\", \"sample_sheets_prior\", and \"clinical_data\" in there\n",
    "if not analysis_path.endswith('/'):\n",
    "    analysis_path += '/'\n",
    "\n",
    "os.makedirs(analysis_path+'log_files', exist_ok=True)\n",
    "os.makedirs(analysis_path+'log_files/correct_files', exist_ok=True)\n",
    "os.makedirs(analysis_path+'sample_sheets', exist_ok=True)\n",
    "for folder_name in ['manifests', 'sample_sheets_prior', 'clinical_data']:\n",
    "    os.makedirs(analysis_path+f'sample_sheets/{folder_name}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter and select TCGA data from the TCGA GDC data portal as explained in the [\"README.md\"](README.md) file\n",
    "- Follow these steps every time for your new analyses, also when you have new aspects or file types to consider later on\n",
    "- Fill the folders \"manifests\" and \"sample_sheets_prior\" (optional: \"clinical_data\") in your \"sample_sheets\" folder in your analysis path with the according files\n",
    "- Adapt the [\"data/config.yaml\"](data/config.yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check validity of configuration file entries\n",
    "- Checks whether all files and file paths listed in the configuration file are existent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "start_time = time.strftime('%Y-%m-%d_%H:%M:%S', time.localtime())\n",
    "\n",
    "input_config = 'data/config.yaml'\n",
    "out_correct_file = analysis_path + f'log_files/correct_files/{start_time}_config_file_correct.txt'\n",
    "log_file = analysis_path + f'log_files/{start_time}_check_config_file_log.txt'\n",
    "\n",
    "%run -nt 'scripts_TCGA_pipeline/01_check_config_file.py' {input_config} {out_correct_file} {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Combine manifest file(s) with sample sheet, filter for relevant files to download\n",
    "- This script merges the manifest file(s) and the sample sheet.\n",
    "- If previous selection of case IDs is wanted, the script filters for specific case IDs of a previous analysis.\n",
    "- Creates adapted filtered manifest file for gdc-client download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = 'data/config.yaml'\n",
    "out_correct_file = analysis_path + f'log_files/correct_files/{start_time}_combine_manifest_sample_sheet_correct.txt'\n",
    "log_file = analysis_path + f'log_files/{start_time}_combine_manifest_sample_sheet_log.txt'\n",
    "\n",
    "%run -nt 'scripts_TCGA_pipeline/02_combine_manifest_sample_sheet.py' {input_config} {out_correct_file} {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download TCGA data via a manifest document and the GDC-client tool\n",
    "- The script creates a new conda environment called \"gdc_client\" and downloads the gdc-client tool. If you have already installed the gdc-client in a separete conda environment, you can specify that in the configuration file.\n",
    "- The script downloads the TCGA data from manifest(s) specified in previous steps and/or the configuration file via the gdc-client.\n",
    "- The files from the manifest are downloaded into the following folder: \\<your analysis_path\\> + '00_raw_data'\n",
    "- Download TCGA data via the gdc-client tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = 'data/config.yaml'\n",
    "log_files_gdc_prefix = analysis_path + f'log_files/{start_time}_gdc_client_log'\n",
    "out_correct_file = analysis_path + f'log_files/correct_files/{start_time}_combine_manifest_sample_sheet_correct.txt'\n",
    "log_file = analysis_path + f'log_files/{start_time}_combine_manifest_sample_sheet_log.txt'\n",
    "\n",
    "%run -nt 'scripts_TCGA_pipeline/03_download_TCGA_data.py' {input_config} {log_files_gdc_prefix} {out_correct_file} {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rename file names\n",
    "- This script changes the suffix to the case id.\n",
    "- The downloaded files are renamed and sorted in new folders for each analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = 'data/config.yaml'\n",
    "out_correct_file = analysis_path + f'log_files/correct_files/{start_time}_rename_files_correct.txt'\n",
    "log_file = analysis_path + f'log_files/{start_time}_rename_files_log.txt'\n",
    "\n",
    "%run -nt 'scripts_TCGA_pipeline/04_rename_files.py' {input_config} {out_correct_file} {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analyze files with separate Snakemake pipeline (Snakefile_sample_analysis)\n",
    "- A Snakemake pipeline can be used to analyze all downloaded data at once (if wanted).\n",
    "- The Snakemake pipeline is a template and is not ready to use for your analysis.\n",
    "- Please adapt the rules for all of your methods in the Snakefile_sample_analysis to use Snakemake.\n",
    "- Each rule requires a Python script with the analysis methods or an adapted shell command in the rule.\n",
    "- The Python scripts for the analysis are located in the folder \"scripts_snakemake\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "input_config = 'data/config.yaml'\n",
    "\n",
    "with open(input_config, 'r') as streamfile:\n",
    "    config_file = yaml.load(streamfile, Loader=yaml.FullLoader)\n",
    "\n",
    "conda_snakemake = config_file['conda_snakemake']\n",
    "snakemake_threads = config_file['snakemake_threads']\n",
    "snakemake_methods = config_file['snakemake_methods']\n",
    "\n",
    "os.makedirs(analysis_path+'02_results_raw', exist_ok=True)\n",
    "for m in snakemake_methods:\n",
    "    os.makedirs(analysis_path+'02_results_raw/'+m, exist_ok=True)\n",
    "os.makedirs(analysis_path+'03_results_combined', exist_ok=True)\n",
    "\n",
    "# run Snakemake pipeline\n",
    "command_snakemake = f'conda run -n {conda_snakemake} snakemake --cores {snakemake_threads} --use-conda -k'\n",
    "process_snakemake = subprocess.Popen(command_snakemake, shell=True)\n",
    "process_snakemake.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
